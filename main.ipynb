{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the game data from a CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "### For the first question, to group the various strategies used by the players, we learn the data for each game and player using RandomForestClassifier. We then use this model to check if this same model predicts the moves of some other player upto 82% accuracy. If this is the case then the code classifies the strategies used by those two players as the same strategy. This is the done for the whole dataset i.e. all of the games and the corresponding model for each strategy is stored. The featured used for training the RandomForestClassifier is the trust percentage of the opponent uptil that point and the previous 10 moves of both players. Finally the count of the distinct strategies is printed.\n",
    "\n",
    "# Problem 2\n",
    "### The list of players is obtained directly from the previous question as the list of players with same strategies is stored as and when they are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df):\n",
    "    \"\"\"\n",
    "    Extract features from the game data.\n",
    "    \"\"\"\n",
    "    df['p1_action'] = df['p1_action'].apply(lambda x: 1 if x == 'TRUST' else 0)\n",
    "    df['p2_action'] = df['p2_action'].apply(lambda x: 1 if x == 'TRUST' else 0)\n",
    "\n",
    "    # Calculate the cumulative sum of TRUST actions for each player and the cumulative number of turns\n",
    "    df['p1_cum_trust'] = df.groupby('game_id')['p1_action'].cumsum()\n",
    "    df['p2_cum_trust'] = df.groupby('game_id')['p2_action'].cumsum()\n",
    "    df['cum_turns'] = df.groupby('game_id').cumcount() + 1  # +1 because cumcount starts from 0\n",
    "\n",
    "    # Calculate the total percent of TRUST for each player up to that turn\n",
    "    df['p1_trust_percent'] = df['p1_cum_trust'] / df['cum_turns']\n",
    "    df['p2_trust_percent'] = df['p2_cum_trust'] / df['cum_turns']\n",
    "    for i in range(1, 11):\n",
    "        # Shift the actions to get the last i moves, filling missing values with a placeholder (-1)\n",
    "        df[f'p1_move_{i}'] = df.groupby('game_id')['p1_action'].shift(i-1).fillna(-1).astype(int)\n",
    "        df[f'p2_move_{i}'] = df.groupby('game_id')['p2_action'].shift(i-1).fillna(-1).astype(int)\n",
    "        df_p1 = df.copy()\n",
    "    df_p2 = df.copy()\n",
    "\n",
    "    # Add 'player' and 'action' columns for p1 and p2 rows\n",
    "    df_p1['player'] = df_p1['p1_id']\n",
    "    df_p1['action'] = df_p1['p1_action']\n",
    "\n",
    "    df_p2['player'] = df_p2['p2_id']\n",
    "    df_p2['action'] = df_p2['p2_action']\n",
    "\n",
    "    # Combine the two dataframes\n",
    "    df_combined = pd.concat([df_p1, df_p2], ignore_index=True)\n",
    "\n",
    "    # Sort the dataframe by 'player'\n",
    "    df_combined_sorted = df_combined.sort_values(by=['player', 'game_id'])\n",
    "    df_grouped = df_combined_sorted.groupby(['player', 'game_id']).apply(lambda x: x.iloc[10:]).reset_index(drop=True)\n",
    "\n",
    "    # For each 'game_id' for each 'player', remove the first 10 columns for every 'game_id', retaining only 'player', 'game_id', and the new 'action'\n",
    "\n",
    "    # Display the first few rows of the transformed dataframe to verify the changes\n",
    "    ##print(df)\n",
    "\n",
    "\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X,y):\n",
    "    feature_columns = ['p1_cum_trust', 'p2_cum_trust'] + [f'p1_move_{i}' for i in range(1, 11)] + [f'p2_move_{i}' for i in range(1, 11)]\n",
    "    ##X = df.loc[10:57, feature_columns]  # Python uses zero-based indexing, so row 11 is at index 10, and we use 57 to include row 58\n",
    "    ##y = df.loc[10:57, 'p1_action'].shift(-1).fillna(-1)  # Adjust y accordingly\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(f'Accuracy: {accuracy:.2f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_strategy(df):\n",
    "    \"\"\"\n",
    "    Group players by their identified strategies.\n",
    "    \"\"\"\n",
    "    # This example assumes that the 'strategy' column has been filled with identified strategy names or IDs.\n",
    "    strategy_groups = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        strategy_groups[row['strategy']].append(row['p1_id'])\n",
    "        strategy_groups[row['strategy']].append(row['p2_id'])\n",
    "\n",
    "    # Remove duplicate player IDs in each strategy group and sort\n",
    "    for strategy, players in strategy_groups.items():\n",
    "        strategy_groups[strategy] = sorted(list(set(players)))\n",
    "    \n",
    "    # Convert the strategy groups from a dictionary to a list of lists\n",
    "    grouped_strategies = list(strategy_groups.values())\n",
    "    \n",
    "    # Sort the list of lists based on the smallest player ID in each group\n",
    "    grouped_strategies.sort(key=lambda x: x[0])\n",
    "    \n",
    "    return grouped_strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(df, model,num, total_num, player1,total_set):\n",
    "    fit_counter = 0\n",
    "    feature_columns = ['p1_cum_trust', 'p2_cum_trust'] + [f'p1_move_{i}' for i in range(1, 11)] + [f'p2_move_{i}' for i in range(1, 11)]\n",
    "    set = []\n",
    "    num+=1\n",
    "    set.append(player1)\n",
    "    total_set.append(player1)\n",
    "    # Iterate through each group of games by player\n",
    "    for player, group in df.groupby('player'):\n",
    "        # Selecting features and labels\n",
    "        game_X = group[feature_columns]  # Correct way to select features\n",
    "        game_y = group['action']  # Assuming 'action' is the correct label column based on your transformation\n",
    "        \n",
    "        # Check if there are enough data points to predict and calculate accuracy\n",
    "        if len(game_X) > 0:\n",
    "            game_y_pred = model.predict(game_X)\n",
    "            \n",
    "            # Calculating accuracy for the current player's games\n",
    "            accuracy = accuracy_score(game_y, game_y_pred)\n",
    "            \n",
    "            # Increment the counter if the accuracy meets a certain threshold, e.g., > 0.7\n",
    "            if accuracy > 0.82:\n",
    "                if(player not in total_set):\n",
    "                    fit_counter += 1\n",
    "                    num += 1\n",
    "                    set.append(player)\n",
    "                    total_set.append(player)\n",
    "\n",
    "    return num, set, total_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Path to your dataset\n",
    "    file_path = 'input_game.csv'\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = load_data(file_path)\n",
    "    df = feature_extraction(df)\n",
    "    feature_columns = ['p1_cum_trust', 'p2_cum_trust'] + [f'p1_move_{i}' for i in range(1, 11)] + [f'p2_move_{i}' for i in range(1, 11)]\n",
    "    total_set = []\n",
    "    num = 0\n",
    "    count = 0\n",
    "    models = []\n",
    "    final_out=[]\n",
    "    total_num = pd.concat([df['p1_id'], df['p2_id']]).nunique()\n",
    "    for player, group in df.groupby('player'):\n",
    "        if player not in total_set:\n",
    "            player_X = group[feature_columns]  # Features for the player across all their games\n",
    "            player_y = group['action'].shift(-1).fillna(-1)  # Target for the player, shifting actions to predict the next action\n",
    "            model = model_train(player_X, player_y)  # Train the model for the player\n",
    "            num,set, total_set = model_fit(df, model,num,total_num,player,total_set)  # Fit the model for the player, assuming '1' is a parameter for model_fit\n",
    "            if len(set) < 3:\n",
    "                for player in set:\n",
    "                    total_set.remove(player)\n",
    "                continue\n",
    "            #print(player)\n",
    "            models.append(model)\n",
    "            set.sort()\n",
    "            #print(set)\n",
    "            final_out.append(set)\n",
    "            count+=1\n",
    "            #print(num)\n",
    "    final_out = sorted(final_out, key=lambda x: x[0])\n",
    "    print(final_out)\n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5, 7, 9, 13, 15, 19, 20, 25, 27, 33, 34, 36, 37, 39, 53, 55, 60, 65, 76, 87, 95, 100, 104, 105, 110, 118, 121, 126, 128, 129, 136, 137, 141, 143, 146, 149, 150, 158, 172, 175, 178, 181, 192, 193, 194, 200], [6, 8, 16, 24, 29, 30, 32, 41, 43, 47, 50, 52, 59, 61, 62, 66, 70, 73, 81, 84, 86, 88, 89, 91, 94, 101, 102, 107, 109, 116, 117, 120, 125, 133, 134, 135, 139, 142, 144, 145, 153, 156, 157, 162, 166, 170, 171, 174, 176, 183, 184, 185, 187, 195], [10, 83, 119, 124, 173], [14, 22, 23, 38, 57, 64, 85, 96, 97, 108, 111, 115, 131, 148, 155, 167, 189, 197], [42, 54, 58, 74, 75, 80, 93, 130, 147, 164, 179, 199], [45, 56, 67, 77, 79, 92, 103, 113, 138, 152, 159, 161, 168, 169, 180, 182, 188, 190]]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# If running as a script, execute the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the list of players with the same strategy and the total count is 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_game(strategy1, strategy2, num_rounds):\n",
    "    \"\"\"\n",
    "    Simulates a game between two strategies for a fixed number of rounds.\n",
    "    \n",
    "    :param strategy1: The first player's strategy/model.\n",
    "    :param strategy2: The second player's strategy/model.\n",
    "    :param num_rounds: Number of rounds to play.\n",
    "    :return: The total score for both strategies.\n",
    "    \"\"\"\n",
    "    # Initialize scores\n",
    "    score1, score2 = 0, 0\n",
    "    \n",
    "    # Reward matrix\n",
    "    rewards = {\n",
    "        ('Trust', 'Trust'): (2, 2),\n",
    "        ('Cheat', 'Cheat'): (0, 0),\n",
    "        ('Trust', 'Cheat'): (-1, 3),\n",
    "        ('Cheat', 'Trust'): (3, -1),\n",
    "    }\n",
    "    \n",
    "    for _ in range(num_rounds):\n",
    "        action1 = predict_action(strategy1)  # You need to define how to predict actions based on your model\n",
    "        action2 = predict_action(strategy2)\n",
    "        \n",
    "        # Update scores based on actions\n",
    "        result = rewards[(action1, action2)]\n",
    "        score1 += result[0]\n",
    "        score2 += result[1]\n",
    "    \n",
    "    return score1, score2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(strategies, num_games, num_rounds):\n",
    "    \"\"\"\n",
    "    Runs a Monte Carlo simulation where each strategy competes against every other.\n",
    "    \n",
    "    :param strategies: List of strategies/models.\n",
    "    :param num_games: Number of games each pair of strategies will play.\n",
    "    :param num_rounds: Number of rounds in each game.\n",
    "    \"\"\"\n",
    "    results = {}  # Store the total score for each strategy\n",
    "    \n",
    "    for i, strategy1 in enumerate(strategies):\n",
    "        for j, strategy2 in enumerate(strategies):\n",
    "            total_score1, total_score2 = 0, 0\n",
    "            \n",
    "            # Play num_games games between strategy1 and strategy2\n",
    "            for _ in range(num_games):\n",
    "                score1, score2 = simulate_game(strategy1, strategy2, num_rounds)\n",
    "                total_score1 += score1\n",
    "                total_score2 += score2\n",
    "            \n",
    "            # Update the results\n",
    "            results[(i, j)] = (total_score1, total_score2)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for 5 rounds per game:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_simulation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m round_options \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m]  \u001b[38;5;66;03m# Different numbers of rounds per game to simulate\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Run the simulation for various round options\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[43mrun_simulation_for_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgames_per_matchup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m, in \u001b[0;36mrun_simulation_for_rounds\u001b[1;34m(strategies, games_per_matchup, round_options)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rounds_per_game \u001b[38;5;129;01min\u001b[39;00m round_options:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrounds_per_game\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rounds per game:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     simulation_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_simulation\u001b[49m(strategies, games_per_matchup, rounds_per_game)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m matchup, scores \u001b[38;5;129;01min\u001b[39;00m simulation_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_simulation' is not defined"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "# Strategy functions modified to accept a history of moves\n",
    "def always_trust(history):\n",
    "    return \"Trust\"\n",
    "\n",
    "def always_cheat(history):\n",
    "    return \"Cheat\"\n",
    "\n",
    "def tit_for_tat(history):\n",
    "    if not history or history[-1] == \"Trust\":\n",
    "        return \"Trust\"\n",
    "    return \"Cheat\"\n",
    "\n",
    "def half_cheat(history):\n",
    "    recent_moves = history[-4:]\n",
    "    if recent_moves.count(\"Cheat\") >= 2:\n",
    "        return \"Cheat\"\n",
    "    return \"Trust\"\n",
    "\n",
    "def alternate_cheat(history):\n",
    "    if len(history) % 2 == 0:\n",
    "        return \"Cheat\"\n",
    "    return \"Trust\"\n",
    "\n",
    "def random_choice(history):\n",
    "    return random.choice([\"Trust\", \"Cheat\"])\n",
    "\n",
    "# Adjust play_round to accept and update history\n",
    "def play_round(strategy1, strategy2, history1, history2):\n",
    "    action1 = strategy1(history1)\n",
    "    action2 = strategy2(history2)\n",
    "    return get_rewards(action1, action2), action1, action2\n",
    "\n",
    "# Adjust play_game to maintain histories\n",
    "def play_game(strategy1, strategy2, rounds):\n",
    "    total_reward1, total_reward2 = 0, 0\n",
    "    history1, history2 = [], []\n",
    "    for _ in range(rounds):\n",
    "        (reward1, reward2), action1, action2 = play_round(strategy1, strategy2, history1, history2)\n",
    "        total_reward1 += reward1\n",
    "        total_reward2 += reward2\n",
    "        history1.append(action1)\n",
    "        history2.append(action2)\n",
    "    return total_reward1, total_reward2\n",
    "\n",
    "# Run the simulation for a range of rounds\n",
    "def run_simulation_for_rounds(strategies, games_per_matchup, round_options):\n",
    "    for rounds_per_game in round_options:\n",
    "        print(f\"\\nResults for {rounds_per_game} rounds per game:\")\n",
    "        simulation_results = run_simulation(strategies, games_per_matchup, rounds_per_game)\n",
    "\n",
    "        # Print the results\n",
    "        for matchup, scores in simulation_results.items():\n",
    "            print(f\"{matchup}: {scores}\")\n",
    "\n",
    "        # Rank strategies based on total rewards\n",
    "        total_scores = {}\n",
    "        for matchup, scores in simulation_results.items():\n",
    "            total_scores[matchup[0]] = total_scores.get(matchup[0], 0) + scores[0]\n",
    "            total_scores[matchup[1]] = total_scores.get(matchup[1], 0) + scores[1]\n",
    "\n",
    "        sorted_scores = sorted(total_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(\"\\nStrategy Ranking (from highest to least rewards):\")\n",
    "        for rank, (strategy, score) in enumerate(sorted_scores, start=1):\n",
    "            print(f\"{rank}. {strategy}: {score}\")\n",
    "\n",
    "# Including all strategies in the simulation\n",
    "strategies = [always_trust, always_cheat, tit_for_tat, half_cheat, alternate_cheat, random_choice]\n",
    "\n",
    "# Simulation parameters\n",
    "games_per_matchup = 100  # Number of games each strategy plays against each other\n",
    "round_options = [5, 10, 15]  # Different numbers of rounds per game to simulate\n",
    "\n",
    "# Run the simulation for various round options\n",
    "run_simulation_for_rounds(strategies, games_per_matchup, round_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
